# Qwen-2.5-VLM Price Predictor

Vision-Language Model for Resale Price Estimation

This project fine-tunes a Qwen-2.5 Vision-Language Model to predict resale prices (INR) from a product image + structured metadata, and deploys it as a FastAPI service using a lightweight LoRA adapter.

The repository covers two complete stages:

Model training & fine-tuning (Jupyter Notebook)

Model deployment as a public REST API

## 1ï¸âƒ£ Model Training (Notebook Workflow)

Training is done in a Google Colab Jupyter Notebook (.ipynb) using GPU.

### ğŸ”¹ Base Model

Qwen/Qwen2.5-VL-3B-Instruct

Multimodal (vision + text) transformer

Supports image understanding with structured prompts

### ğŸ”¹ Training Objective

Given:

ğŸ–¼ï¸ Product image

ğŸ“ Product attributes:

Name

Category

Condition

Age (years of use)

The model learns to output:

ğŸ’° A single numeric resale price (in INR)

### ğŸ”¹ Data Format

Each training example contains:

messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image_path},
                {"type": "text", "text": f"Product: {row['name']}\nBased on the image and product name, predict the final_price. Output only the numeric value."}
            ]
        }
    ]


Key design choice:

Strict numeric outputs to simplify inference and parsing

No explanations, only prices

### ğŸ”¹ Fine-Tuning Strategy (LoRA)

To keep training efficient and VRAM-friendly:

PEFT (LoRA) used instead of full fine-tuning

Only attention layers updated

Base model remains frozen

Benefits:

âœ”ï¸ Much lower GPU memory usage

âœ”ï¸ Faster training

âœ”ï¸ Small adapter size (easy deployment)

### ğŸ”¹ Quantization

4-bit NF4 quantization via bitsandbytes

Enables training & inference on limited GPUs (Colab T4 / L4)

### ğŸ”¹ Training Steps (High Level)

Load base Qwen-2.5-VL model

Apply 4-bit quantization

Attach LoRA adapters

Format multimodal prompts

Train on labeled resale dataset

Save LoRA adapter only to Google Drive

Output:

qwen_price_finetuned/

â”œâ”€â”€ adapter_model.safetensors

â”œâ”€â”€ adapter_config.json


âš ï¸ The base model is not savedâ€”only the LoRA adapter.

## 2ï¸âƒ£ Model Deployment (FastAPI Server)

Deployment is handled by server.py.

The system reconstructs the trained model at runtime using:

Base Qwen-2.5-VL model

Fine-tuned LoRA adapter

### ğŸ”¹ Deployment Architecture

Client (Image + Form Data)
        
FastAPI Server

Qwen-2.5-VL Base Model

LoRA Adapter

Price Prediction (INR)

### ğŸ”¹ Runtime Model Loading

At server startup:

Load Qwen-2.5-VL in 4-bit mode

Load LoRA adapter from Google Drive

Merge adapter into inference pipeline

Prepare processor for images + text

This avoids re-training and keeps startup fast.

### ğŸ”¹ API Endpoint

POST /predict

Inputs (multipart/form-data):

Field	Description
file	Product image
product_name	Product name
category	Product category
condition	New / Used / Damaged
age	Usage in years


 try:
        # We inject the new details into the prompt so the model context includes them.
        prompt_text = (
            f"Analyze this image to estimate the resale price.\\n"
            f"Product Name: {{product_name}}\\n"
            f"Category: {{category}}\\n"
            f"Condition: {{condition}}\\n"
            f"Usage Duration: {{age}} years\\n"
            f"Task: Based on the visual evidence and these details, predict the final_price in INR. Output only the numeric value."
        )
        messages = [
            {{
                "role": "user",
                "content": [
                    {{"type": "image", "image": image}},
                    {{"type": "text", "text": prompt_text}}
                ]
            }}
        ]
        
        
### ğŸ”¹ Inference Flow

Image is processed by vision encoder

Text prompt is dynamically constructed

Model generates output text

Price is parsed as an integer

JSON response is returned

### ğŸ”¹ Example Response
{
  "product": "iPhone 12",
  "predicted_price": 28500,
  "currency": "INR",
  "raw_model_output": "28500"
}

# ğŸš€ Running the Server (Colab)
## 1ï¸âƒ£ Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')


Ensure adapter path exists:

/content/drive/MyDrive/qwen_price_finetuned

## 2ï¸âƒ£ Configure ngrok

Set your token in server.py:

NGROK_AUTH_TOKEN = "YOUR_TOKEN"

## 3ï¸âƒ£ Start the API
python server.py


Access:

API Base URL â†’ ngrok URL

Swagger UI â†’ /docs

## âš™ï¸ Key Design Choices

LoRA instead of full fine-tuning

Strict numeric outputs

Colab-friendly deployment

Vision + structured metadata fusion

These choices make the system:

Fast to train

Cheap to deploy

Easy to demo

Easy to extend

## ğŸ§ª Limitations

Designed for single-image inference

Not production-hardened (open CORS, ngrok)

Dataset quality directly affects pricing accuracy

Price prediction is deterministic, not probabilistic
